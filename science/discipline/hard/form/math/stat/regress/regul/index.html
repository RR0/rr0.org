<!--#include virtual="/header-start.html" -->
<title>Régularisation</title>
<!--#include virtual="/header-end.html" -->
<p><i lang="en">Regularization</i>.</p>
<section>
  <h2>Motivation</h2>
  <p>Atténuer la précision d'une hypothèse de modèle.</p>
</section>
<section>
  <h2>Analyse</h2>
  <p>Lors d'un <a href="../cost">calcul de coût</a> d'une hypothèse, un coût nul ne signifie pas forcément que
    l'hypothèse est excellente. Cela peut plutôt paraître suspect et demande une vérification qu'il ne s'agit pas d'un
    cas de <strong><em><a href="../overfit">surapprentissage</a></em></strong>.
  </p>
</section>
<section>
  <h2>Conception</h2>
  <p>On ajoute à la <a href="../cost">fonction de coût</a> une surévaluation de paramètres. Par ex :</p>
  <p>`J = 1/m sum_(i=1)^m c(h_Θ, y) + λ sum_(j=1)^n θ_j^2`</p>
  <p>ce qui ajoute au coût une pénalité qui augmente d'autant que les paramètres `Θ` augmente, et où `λ` doit être
    suffisamment grand (1000 par ex) mais pas trop (sinon <i
        lang="en"><a href="../underfit">sous-apprentissage</a></i>) pour que la minimisation du coût fasse tendre les
    `θ` vers zéro.</p>
  <p>À noter que `θ_0` ne doit pas être régularisé.</p>
  <section>
    <h3>Vectorisation</h3>
    <p>`sum_(j=1)^n θ_j^2` est équivalent à `θ^Tθ` (toujours en ignorant `θ_0`).</p>
  </section>
</section>
<!--#include virtual="/footer.html" -->
<style>.mjx-math * {
  line-height: 0;
}</style>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=AM_CHTML"></script>
